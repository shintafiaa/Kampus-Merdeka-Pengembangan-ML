{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2 Neural Network Binary Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOw7DDCC7s2jHBxPcWNmXGT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shintafiaa/Kampus-Merdeka-Pengembangan-ML/blob/main/2_Neural_Network_Binary_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juT3_EKlfYlG"
      },
      "source": [
        "TAHAP MEMPROSES DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49k_TPbRdAO8"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('citrus.csv')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtLJP2pZdTl2",
        "outputId": "6bb28abb-6159-43db-8ecd-fc1612004d22"
      },
      "source": [
        "#melihat overview dataset\n",
        "df.info()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 6 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   name      10000 non-null  object \n",
            " 1   diameter  10000 non-null  float64\n",
            " 2   weight    10000 non-null  float64\n",
            " 3   red       10000 non-null  int64  \n",
            " 4   green     10000 non-null  int64  \n",
            " 5   blue      10000 non-null  int64  \n",
            "dtypes: float64(2), int64(3), object(1)\n",
            "memory usage: 468.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ImpXGUYkdbAl",
        "outputId": "ee20e704-9226-4665-a753-1d7cafd16213"
      },
      "source": [
        "df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>diameter</th>\n",
              "      <th>weight</th>\n",
              "      <th>red</th>\n",
              "      <th>green</th>\n",
              "      <th>blue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>orange</td>\n",
              "      <td>2.96</td>\n",
              "      <td>86.76</td>\n",
              "      <td>172</td>\n",
              "      <td>85</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>orange</td>\n",
              "      <td>3.91</td>\n",
              "      <td>88.05</td>\n",
              "      <td>166</td>\n",
              "      <td>78</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>orange</td>\n",
              "      <td>4.42</td>\n",
              "      <td>95.17</td>\n",
              "      <td>156</td>\n",
              "      <td>81</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>orange</td>\n",
              "      <td>4.47</td>\n",
              "      <td>95.60</td>\n",
              "      <td>163</td>\n",
              "      <td>81</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>orange</td>\n",
              "      <td>4.48</td>\n",
              "      <td>95.76</td>\n",
              "      <td>161</td>\n",
              "      <td>72</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>grapefruit</td>\n",
              "      <td>15.35</td>\n",
              "      <td>253.89</td>\n",
              "      <td>149</td>\n",
              "      <td>77</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>grapefruit</td>\n",
              "      <td>15.41</td>\n",
              "      <td>254.67</td>\n",
              "      <td>148</td>\n",
              "      <td>68</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>grapefruit</td>\n",
              "      <td>15.59</td>\n",
              "      <td>256.50</td>\n",
              "      <td>168</td>\n",
              "      <td>82</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>grapefruit</td>\n",
              "      <td>15.92</td>\n",
              "      <td>260.14</td>\n",
              "      <td>142</td>\n",
              "      <td>72</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>grapefruit</td>\n",
              "      <td>16.45</td>\n",
              "      <td>261.51</td>\n",
              "      <td>152</td>\n",
              "      <td>74</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            name  diameter  weight  red  green  blue\n",
              "0         orange      2.96   86.76  172     85     2\n",
              "1         orange      3.91   88.05  166     78     3\n",
              "2         orange      4.42   95.17  156     81     2\n",
              "3         orange      4.47   95.60  163     81     4\n",
              "4         orange      4.48   95.76  161     72     9\n",
              "...          ...       ...     ...  ...    ...   ...\n",
              "9995  grapefruit     15.35  253.89  149     77    20\n",
              "9996  grapefruit     15.41  254.67  148     68     7\n",
              "9997  grapefruit     15.59  256.50  168     82    20\n",
              "9998  grapefruit     15.92  260.14  142     72    11\n",
              "9999  grapefruit     16.45  261.51  152     74     2\n",
              "\n",
              "[10000 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXaqud_WdlDc",
        "outputId": "56ec838b-5709-4576-8174-bdafba2ab974"
      },
      "source": [
        "#ubah string ke tipe data numerik\n",
        "#string 'orange' diubah menjadi 0\n",
        "#string 'grape' diubah menjadi 1\n",
        "df.name[df.name == 'orange'] = 0\n",
        "df.name[df.name == 'grapefruit'] = 1"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "2Ky6jcLEd6Jt",
        "outputId": "8ad1263f-73a4-457a-ad91-c8f8ceb45a2f"
      },
      "source": [
        "df"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>diameter</th>\n",
              "      <th>weight</th>\n",
              "      <th>red</th>\n",
              "      <th>green</th>\n",
              "      <th>blue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2.96</td>\n",
              "      <td>86.76</td>\n",
              "      <td>172</td>\n",
              "      <td>85</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>3.91</td>\n",
              "      <td>88.05</td>\n",
              "      <td>166</td>\n",
              "      <td>78</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>4.42</td>\n",
              "      <td>95.17</td>\n",
              "      <td>156</td>\n",
              "      <td>81</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>4.47</td>\n",
              "      <td>95.60</td>\n",
              "      <td>163</td>\n",
              "      <td>81</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4.48</td>\n",
              "      <td>95.76</td>\n",
              "      <td>161</td>\n",
              "      <td>72</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>1</td>\n",
              "      <td>15.35</td>\n",
              "      <td>253.89</td>\n",
              "      <td>149</td>\n",
              "      <td>77</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>1</td>\n",
              "      <td>15.41</td>\n",
              "      <td>254.67</td>\n",
              "      <td>148</td>\n",
              "      <td>68</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>1</td>\n",
              "      <td>15.59</td>\n",
              "      <td>256.50</td>\n",
              "      <td>168</td>\n",
              "      <td>82</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>1</td>\n",
              "      <td>15.92</td>\n",
              "      <td>260.14</td>\n",
              "      <td>142</td>\n",
              "      <td>72</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>1</td>\n",
              "      <td>16.45</td>\n",
              "      <td>261.51</td>\n",
              "      <td>152</td>\n",
              "      <td>74</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     name  diameter  weight  red  green  blue\n",
              "0       0      2.96   86.76  172     85     2\n",
              "1       0      3.91   88.05  166     78     3\n",
              "2       0      4.42   95.17  156     81     2\n",
              "3       0      4.47   95.60  163     81     4\n",
              "4       0      4.48   95.76  161     72     9\n",
              "...   ...       ...     ...  ...    ...   ...\n",
              "9995    1     15.35  253.89  149     77    20\n",
              "9996    1     15.41  254.67  148     68     7\n",
              "9997    1     15.59  256.50  168     82    20\n",
              "9998    1     15.92  260.14  142     72    11\n",
              "9999    1     16.45  261.51  152     74     2\n",
              "\n",
              "[10000 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugy_JEqBeCBw"
      },
      "source": [
        "#ubah dataframe ke numpy array supaya dapat diproses oleh model\n",
        "dataset = df.values"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEg_5uuXeRks",
        "outputId": "bee71ec5-04b1-4141-bb32-013e9d29c2fb"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 2.96, 86.76, 172, 85, 2],\n",
              "       [0, 3.91, 88.05, 166, 78, 3],\n",
              "       [0, 4.42, 95.17, 156, 81, 2],\n",
              "       ...,\n",
              "       [1, 15.59, 256.5, 168, 82, 20],\n",
              "       [1, 15.92, 260.14, 142, 72, 11],\n",
              "       [1, 16.45, 261.51, 152, 74, 2]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGX7QOcLeUoU"
      },
      "source": [
        "# pilih 4 kolom terakhir sebagai atribut\n",
        "X = dataset[:,1:6]\n",
        "# bilangan sebelum koma untuk memilih baris pada dataframe\n",
        "# bilangan setelah koma untuk memilih kolom pada dataframe"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACsglQuDerPT"
      },
      "source": [
        "#label\n",
        "y = dataset[:,0]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2CEH0qfexOW",
        "outputId": "088a043b-f62b-4f96-a29d-2d75e8b35e7b"
      },
      "source": [
        "# Normalization\n",
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.74025974, 0.63529412, 0.        ],\n",
              "       [0.07042254, 0.00738197, 0.66233766, 0.55294118, 0.01851852],\n",
              "       [0.10822832, 0.04812589, 0.53246753, 0.58823529, 0.        ],\n",
              "       ...,\n",
              "       [0.93624907, 0.97133047, 0.68831169, 0.6       , 0.33333333],\n",
              "       [0.96071164, 0.99216023, 0.35064935, 0.48235294, 0.16666667],\n",
              "       [1.        , 1.        , 0.48051948, 0.50588235, 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBDGw1nCe-BE"
      },
      "source": [
        "# pisahkan data training dan testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_scale, y, test_size=0.3)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwpm2dRQfJR_"
      },
      "source": [
        "#ubah tipe data boolean ke float32 pada label\n",
        "import numpy as np #sudah diimport di atas, hanya untuk belajar\n",
        " \n",
        "Y_train = Y_train.astype(np.float32)\n",
        "Y_test = Y_test.astype(np.float32)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQjc_hugfbKE"
      },
      "source": [
        "MEMBANGUN MODEL JARINGAN SYARAF TIRUAN (JST)/NEURAL NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N64Cnx__fVwh"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIPKBXCbfpep"
      },
      "source": [
        "model = Sequential([    \n",
        "                    Dense(32, activation='relu', input_shape=(5,)),    \n",
        "                    Dense(32, activation='relu'),    \n",
        "                    Dense(1, activation='sigmoid'),]) #Sigmoid memetakan probabilitas dari 0 ke 1, cocok untuk klasifikasi"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGHjIA-Lf4oq"
      },
      "source": [
        "model.compile(optimizer='sgd',\n",
        "              loss='binary_crossentropy', #kasus binary classification\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiSlYQC2f_qJ",
        "outputId": "2b46aace-822c-44b8-8b6d-11f22d4a6af5"
      },
      "source": [
        "model.fit(X_train, Y_train, epochs=100)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "219/219 [==============================] - 1s 2ms/step - loss: 0.6707 - accuracy: 0.7869\n",
            "Epoch 2/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.6425 - accuracy: 0.8897\n",
            "Epoch 3/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.6034 - accuracy: 0.8990\n",
            "Epoch 4/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.5425 - accuracy: 0.9077\n",
            "Epoch 5/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.9120\n",
            "Epoch 6/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.3692 - accuracy: 0.9163\n",
            "Epoch 7/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.2995 - accuracy: 0.9209\n",
            "Epoch 8/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.2549 - accuracy: 0.9206\n",
            "Epoch 9/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.2285 - accuracy: 0.9211\n",
            "Epoch 10/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.2122 - accuracy: 0.9221\n",
            "Epoch 11/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.2026 - accuracy: 0.9233\n",
            "Epoch 12/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9246\n",
            "Epoch 13/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9249\n",
            "Epoch 14/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.9253\n",
            "Epoch 15/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1882 - accuracy: 0.9249\n",
            "Epoch 16/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.9257\n",
            "Epoch 17/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1859 - accuracy: 0.9239\n",
            "Epoch 18/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1853 - accuracy: 0.9257\n",
            "Epoch 19/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.9241\n",
            "Epoch 20/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.9250\n",
            "Epoch 21/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.9247\n",
            "Epoch 22/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.9246\n",
            "Epoch 23/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.9254\n",
            "Epoch 24/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.9237\n",
            "Epoch 25/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.9243\n",
            "Epoch 26/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.9246\n",
            "Epoch 27/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.9247\n",
            "Epoch 28/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1833 - accuracy: 0.9251\n",
            "Epoch 29/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.9246\n",
            "Epoch 30/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.9246\n",
            "Epoch 31/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9250\n",
            "Epoch 32/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.9250\n",
            "Epoch 33/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.9241\n",
            "Epoch 34/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.9256\n",
            "Epoch 35/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 0.9256\n",
            "Epoch 36/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9243\n",
            "Epoch 37/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.9244\n",
            "Epoch 38/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.9259\n",
            "Epoch 39/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.9259\n",
            "Epoch 40/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.9241\n",
            "Epoch 41/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.9249\n",
            "Epoch 42/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.9263\n",
            "Epoch 43/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9249\n",
            "Epoch 44/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.9239\n",
            "Epoch 45/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.9247\n",
            "Epoch 46/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9247\n",
            "Epoch 47/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.9259\n",
            "Epoch 48/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.9233\n",
            "Epoch 49/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9246\n",
            "Epoch 50/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9249\n",
            "Epoch 51/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9250\n",
            "Epoch 52/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 0.9250\n",
            "Epoch 53/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.9251\n",
            "Epoch 54/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1828 - accuracy: 0.9253\n",
            "Epoch 55/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9244\n",
            "Epoch 56/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1828 - accuracy: 0.9261\n",
            "Epoch 57/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9260\n",
            "Epoch 58/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1828 - accuracy: 0.9254\n",
            "Epoch 59/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1828 - accuracy: 0.9244\n",
            "Epoch 60/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.9244\n",
            "Epoch 61/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.9259\n",
            "Epoch 62/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.9256\n",
            "Epoch 63/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9247\n",
            "Epoch 64/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.9250\n",
            "Epoch 65/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.9266\n",
            "Epoch 66/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.9251\n",
            "Epoch 67/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.9263\n",
            "Epoch 68/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1816 - accuracy: 0.9250\n",
            "Epoch 69/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.9256\n",
            "Epoch 70/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 0.9243\n",
            "Epoch 71/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.9263\n",
            "Epoch 72/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.9241\n",
            "Epoch 73/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.9244\n",
            "Epoch 74/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9256\n",
            "Epoch 75/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.9244\n",
            "Epoch 76/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.9256\n",
            "Epoch 77/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 0.9244\n",
            "Epoch 78/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.9251\n",
            "Epoch 79/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 0.9264\n",
            "Epoch 80/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.9240\n",
            "Epoch 81/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9266\n",
            "Epoch 82/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.9259\n",
            "Epoch 83/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9247\n",
            "Epoch 84/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9249\n",
            "Epoch 85/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 0.9253\n",
            "Epoch 86/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.9254\n",
            "Epoch 87/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9251\n",
            "Epoch 88/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.9249\n",
            "Epoch 89/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.9251\n",
            "Epoch 90/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.9254\n",
            "Epoch 91/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.9254\n",
            "Epoch 92/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.9256\n",
            "Epoch 93/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9254\n",
            "Epoch 94/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.9263\n",
            "Epoch 95/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.9247\n",
            "Epoch 96/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.9249\n",
            "Epoch 97/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.9239\n",
            "Epoch 98/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9254\n",
            "Epoch 99/100\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.1816 - accuracy: 0.9263\n",
            "Epoch 100/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.9250\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb897d83c10>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpfG5TtjgFjT",
        "outputId": "5510a3d1-71f9-4f48-9eee-2bc6147634c4"
      },
      "source": [
        "model.evaluate(X_test, Y_test)\n",
        "# elemen pertama adalah loss dan elemen kedua adalah akurasi"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 0s 1ms/step - loss: 0.1655 - accuracy: 0.9350\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.16546723246574402, 0.9350000023841858]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}